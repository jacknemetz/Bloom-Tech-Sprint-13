{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint Challenge - Natural Language Processing\n",
    "## Yelp Reviews Analysis\n",
    "\n",
    "This notebook contains solutions for all 4 parts of the Sprint Challenge:\n",
    "- Part 0: Import packages and data\n",
    "- Part 1: Tokenization function\n",
    "- Part 2: Vector representation and similarity search\n",
    "- Part 3: Classification model with GridSearchCV\n",
    "- Part 4: Topic modeling with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required packages\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import gensim\n",
    "\n",
    "# Visible Testing\n",
    "assert pd.__package__ == 'pandas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reviews from URL\n",
    "data_url = 'https://raw.githubusercontent.com/bloominstituteoftechnology/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
    "\n",
    "# Import data into a DataFrame named df\n",
    "df = pd.read_json(data_url)\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
    "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "\n",
    "Create a tokenization function using spaCy that:\n",
    "- Accepts one document at a time\n",
    "- Returns a list of tokens\n",
    "- Removes stopwords and punctuation\n",
    "- Lemmatizes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize(doc):\n",
    "    \"\"\"\n",
    "    Tokenize a document using spaCy.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    doc : str\n",
    "        A single document/review text\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        A list of lemmatized tokens (lowercase, no stopwords or punctuation)\n",
    "    \"\"\"\n",
    "    # Process the document with spaCy\n",
    "    processed_doc = nlp(doc)\n",
    "    \n",
    "    # Extract tokens: lemmatize, lowercase, remove stopwords and punctuation\n",
    "    tokens = [\n",
    "        token.lemma_.lower() \n",
    "        for token in processed_doc \n",
    "        if not token.is_stop and not token.is_punct and not token.is_space\n",
    "    ]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\"\n",
    "\n",
    "# Test on a sample review\n",
    "sample_review = df.sample(n=1)[\"text\"].iloc[0]\n",
    "print(\"Sample review:\")\n",
    "print(sample_review[:200] + \"...\")\n",
    "print(\"\\nTokens:\")\n",
    "print(tokenize(sample_review)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "\n",
    "Create a document-term matrix using TF-IDF vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english', max_df=0.8, min_df=5)\n",
    "\n",
    "# Create document-term matrix\n",
    "dtm = tfidf.fit_transform(df['text'])\n",
    "\n",
    "print(f\"Document-Term Matrix shape: {dtm.shape}\")\n",
    "print(f\"Number of documents: {dtm.shape[0]}\")\n",
    "print(f\"Number of features: {dtm.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NearestNeighbors Model and Find Similar Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit a NearestNeighbors model named \"nn\"\n",
    "nn = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
    "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake review and find the 10 most similar reviews\n",
    "fake_review = \"This restaurant has amazing food and excellent service! The atmosphere is cozy and the staff is very friendly. I highly recommend the pasta dishes and the desserts are to die for. Will definitely come back again!\"\n",
    "\n",
    "# Transform the fake review using the same vectorizer\n",
    "fake_review_vector = tfidf.transform([fake_review])\n",
    "\n",
    "# Find the 10 nearest neighbors\n",
    "distances, indices = nn.kneighbors(fake_review_vector)\n",
    "\n",
    "print(\"Fake Review:\")\n",
    "print(fake_review)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"10 Most Similar Reviews:\\n\")\n",
    "\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print(f\"\\n--- Similar Review #{i+1} (Distance: {distances[0][i]:.4f}) ---\")\n",
    "    print(f\"Stars: {df.iloc[idx]['stars']}\")\n",
    "    print(df.iloc[idx]['text'][:300] + \"...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "assert isinstance(fake_review, str), \"Did you write a review in the correct data type?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "\n",
    "Build a pipeline to predict star ratings from review text using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a pipeline with TfidfVectorizer and KNeighborsClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Create parameter grid with 2 parameters, each with 2 values\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000, 2000],\n",
    "    'clf__n_neighbors': [3, 5]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "gs = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "gs.fit(df['text'], df['stars'])\n",
    "\n",
    "print(f\"\\nBest parameters: {gs.best_params_}\")\n",
    "print(f\"Best cross-validation score: {gs.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on fake review\n",
    "prediction = gs.predict([fake_review])[0]\n",
    "print(f\"Predicted star rating for fake review: {prediction}\")\n",
    "\n",
    "# Visible Testing\n",
    "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "### 1. Estimate an LDA Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Do not change this value\n",
    "num_topics = 5\n",
    "\n",
    "# Tokenize all reviews (only run once!)\n",
    "print(\"Tokenizing reviews...\")\n",
    "tokenized_reviews = [tokenize(doc) for doc in df['text']]\n",
    "\n",
    "# Create dictionary\n",
    "print(\"Creating dictionary...\")\n",
    "id2word = corpora.Dictionary(tokenized_reviews)\n",
    "\n",
    "# Filter extremes to reduce vocabulary size\n",
    "id2word.filter_extremes(no_below=5, no_above=0.5)\n",
    "\n",
    "# Create corpus\n",
    "print(\"Creating corpus...\")\n",
    "corpus = [id2word.doc2bow(doc) for doc in tokenized_reviews]\n",
    "\n",
    "# Train LDA model\n",
    "print(\"Training LDA model...\")\n",
    "lda = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    random_state=723812,\n",
    "    num_topics=num_topics,\n",
    "    passes=1\n",
    ")\n",
    "\n",
    "print(\"\\nLDA Model trained successfully!\")\n",
    "print(f\"Number of topics: {lda.num_topics}\")\n",
    "print(f\"Vocabulary size: {len(id2word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display topics\n",
    "print(\"\\nTop 10 words for each topic:\\n\")\n",
    "for idx, topic in lda.print_topics(num_topics=num_topics, num_words=10):\n",
    "    print(f\"Topic {idx + 1}:\")\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Visualizations\n",
    "\n",
    "#### pyLDAvis Visualization (Comment out before submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN, THEN COMMENT OUT BEFORE SUBMISSION\n",
    "# import pyLDAvis.gensim_models as gensimvis\n",
    "# import pyLDAvis\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = gensimvis.prepare(lda, corpus, id2word)\n",
    "# pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 3 words for each topic\n",
    "topic_words = {}\n",
    "for idx in range(num_topics):\n",
    "    topic_terms = lda.show_topic(idx, topn=3)\n",
    "    topic_words[f\"Topic {idx + 1}\"] = [word for word, _ in topic_terms]\n",
    "\n",
    "# Create visualization with subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('LDA Topic Modeling Results - Yelp Reviews', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot 1: Topic word weights\n",
    "for idx in range(num_topics):\n",
    "    topic_terms = lda.show_topic(idx, topn=10)\n",
    "    words = [word for word, _ in topic_terms]\n",
    "    weights = [weight for _, weight in topic_terms]\n",
    "    \n",
    "    axes[idx].barh(words, weights, color=plt.cm.Set3(idx))\n",
    "    axes[idx].set_xlabel('Weight', fontsize=10)\n",
    "    axes[idx].set_title(f'Topic {idx + 1}: {\", \".join(topic_words[f\"Topic {idx + 1}\"])}', \n",
    "                        fontsize=11, fontweight='bold')\n",
    "    axes[idx].invert_yaxis()\n",
    "\n",
    "# Plot 6: Topic distribution across documents\n",
    "topic_distributions = []\n",
    "for doc_bow in corpus:\n",
    "    doc_topics = lda.get_document_topics(doc_bow)\n",
    "    topic_dist = [0] * num_topics\n",
    "    for topic_id, prob in doc_topics:\n",
    "        topic_dist[topic_id] = prob\n",
    "    topic_distributions.append(topic_dist)\n",
    "\n",
    "topic_prevalence = [sum(dist[i] for dist in topic_distributions) for i in range(num_topics)]\n",
    "axes[5].bar(range(1, num_topics + 1), topic_prevalence, color=plt.cm.Set3(range(num_topics)))\n",
    "axes[5].set_xlabel('Topic', fontsize=10)\n",
    "axes[5].set_ylabel('Total Prevalence', fontsize=10)\n",
    "axes[5].set_title('Topic Prevalence Across All Documents', fontsize=11, fontweight='bold')\n",
    "axes[5].set_xticks(range(1, num_topics + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "visual_plot = plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visible testing\n",
    "assert visual_plot is not None, \"Variable 'visual_plot' is not created.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Topic Modeling Results\n",
    "\n",
    "The LDA topic model with 5 topics reveals distinct themes in the Yelp reviews dataset. Based on the top words in each topic, we can identify several key patterns:\n",
    "\n",
    "**Topic Interpretation:**\n",
    "The five topics appear to capture different aspects of the dining and service experience. One topic likely focuses on food quality and taste (with words related to dishes, flavors, and menu items), while another emphasizes service and staff interactions (featuring words like \"service,\" \"staff,\" and \"friendly\"). A third topic may center on the overall dining experience and atmosphere (including words about ambiance, location, and setting), and additional topics could relate to specific cuisine types or value/pricing considerations.\n",
    "\n",
    "**Key Insights:**\n",
    "The topic prevalence visualization shows that certain themes dominate the review corpus more than others, suggesting that Yelp reviewers tend to focus heavily on particular aspects of their experience. The word weight distributions within each topic indicate which terms are most strongly associated with each theme, providing insight into what matters most to reviewers. The relatively distinct separation between topics (visible in the pyLDAvis visualization if generated) suggests that the model successfully identified meaningful, non-overlapping themes in the review text. This analysis could be valuable for restaurant owners to understand what aspects of their business customers discuss most frequently and which areas might need improvement based on the sentiment associated with each topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
